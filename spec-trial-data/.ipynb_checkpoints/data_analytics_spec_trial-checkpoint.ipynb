{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Top 50 U.S. Fast Food Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's project, we will be using data about fast food restaurants across the U.S. The dataset has been provided to you as a .csv file in the downloaded project materials. \n",
    "\n",
    "Follow along by reading through each step and completing sections labeled \"__TO_DO__\"\n",
    "\n",
    "If you need any help, don't hesistate to reach out in the queue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you work through the project, make sure to run any code cells, whether or not there are \"#__TO_DO__#\" sections inside the cells:\n",
    "\n",
    ">(Hint: when you run the cell below successfully, you should see the output of the print function listed below the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay, you ran this cell!\n"
     ]
    }
   ],
   "source": [
    "print(\"Yay, you ran this cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a Question or Set of Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's project, we will be using data about fast food restaurants across the U.S. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are an entrepreneur who wants to open a fast food franchise. Using the data available to you, you want to answer the following questions:\n",
    "\n",
    "#### 1) What is the distribution of revenue of all companies? \n",
    "#### 2) What is the distribution of the number of units for the companies overall?\n",
    "#### 3) Which companies have the most franchise units (non-company-owned units)?\n",
    "#### 4) Which companies have the most locations combined (franchise + company owned)?Â¶\n",
    "#### 5) Which companies have the highest revenue per unit?\n",
    "#### 6) Is there a correlation between the amount of sales per company and the company's total number of locations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are simple questions. In data analysis, they are known as exploratotry questions. As you move further in your data analytics journey, you'll gain the skills to answer more complex questions and tackle larger problems such as predicting future revenue for a company. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Initial Requirements & Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, initial project outlines will be set such as timelines and objectives. In addition, you'd look for potential data sources to answer your questions. For student data projects, there are many free resources such as kaggle.com or the Google dataset search. In a future career, this might be proprietary company data such as sales and revenue information or consumer information being gathered from website analytic tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project today, we will use a small dataset with information on the franchise units and sales information on the top 50 fast food restaurants in the U.S. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load the dataset, we will use a python library called Pandas. \n",
    "Pandas is one of the main tools used by data analysts to work with data. As you work through this lab, complete the # __TO_DO__ sections as directed. \n",
    "\n",
    "To run cells in Jupyter notebook, simply press SHIFT + ENTER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell. \n",
    "# this imports libraries we will use for data manipulation and visualization\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the data, we will use a pandas method called \"read_csv\" - \n",
    "# this will convert the csv file into a \"dataframe\" which we will save to a variable called \"df\" for reference\n",
    "\n",
    "#__TO_DO__ below:\n",
    "\n",
    "# locate the .csv file from your downloaded materials for this lab. Right-click the file and select \"copy as path.\" \n",
    "\n",
    "# paste the path to the file on your computer in the parenthesis below (format should be (r\"path\") - \n",
    "# in python, writing r before a string is called a raw string, which will ensure non-letter characters won't escape the string)\n",
    "\n",
    "df = pd.read_csv(#_TO_DO__)\n",
    "\n",
    "# after pasting the path in the TO_DO section above, run this cell by pressing SHIFT + ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we clean the data, we want to take an initial look at it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods in pandas we can use to get an initial feel for the data. Some methods include:\n",
    "\n",
    "<ul>\n",
    "    <li>head - looks at the beginning values in the dataframe </li>\n",
    "    <li>tail - looks at the ending values in the dataframe </li> \n",
    "    <li>info - shows basic information in the dataframe including column names, data types, number of rows, etc.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To invoke a method, call the variable (saved earlier as df), then use a \".\" followed by the method name invoked. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the last values in the dataframe by typing the variable name (df)\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the basic information about a dataframe including column names, data types, and number of rows\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You probably noticed some of these column names are messy. \n",
    "\n",
    "There are other issues too, which we will find in the data preparation phase during step 3. We are missing values, column names are hard to read, and the data types of most of the columns are \"objects\" instead of numbers (floats or integers). This is a reality of data analysis. In fact, in the industry it is widely acknowledged that up to 80% of a data analysis project is spent cleaning and preparing the data! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we've taken an initial look at the dataframe, we have some things to clean up before we analyze it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To prepare the data, we need to \"clean\" it. \n",
    "Cleaning data is just making it more usable and easier to work with as we analyze it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tackle the column names first. Follow along with the cells below to clean the columns up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the info method on the dataframe again. You'll see the column names have capital letters, no spaces, and punctuation.\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we can use a python function to remove punctuation and add underscores where there should be spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT + ENTER to run this cell\n",
    "\n",
    "column_list = df.columns.tolist()\n",
    "\n",
    "import re \n",
    "\n",
    "snake_list = []\n",
    "\n",
    "for column in column_list:\n",
    "    column = re.sub(r'(?<!^)(?=[A-Z])', '_', column).lower()\n",
    "    \n",
    "    snake_list.append(column)\n",
    "\n",
    "df.columns = snake_list\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you don't understand everything in this function. That's what you'll be learning in the specialization! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the info method on the dataframe again and see how the column names changed\n",
    "# press SHIFT + ENTER to run this cell\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the \"Dtype\" column on the right side of the information displayed above. \n",
    "\n",
    "This shows the data type of each column in the dataframe. In pandas, \"object\" refers to a string. The problem is, we want the columns with numbers to be actual numbers, not strings, so we can perform calculations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the head method on the dataframe to see the first few rows. \n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we convert the strings into numbers, we need to remove the commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT + ENTER to run this cell\n",
    "# below, we are reassigning the values in the \"sales_in_millions_2019\" column to the same values with the commas removed.\n",
    "\n",
    "df.sales_in_millions_2019 = df.sales_in_millions_2019.str.replace(',', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to go through and remove commas from each of the columns that we want to change into numbers. Use the cell above as a guide and fill in the \"#_TO_DO_#\" sections. \n",
    "\n",
    "To understand more of what we are doing with python to accomplish this, check out these links. \n",
    "\n",
    "Replace method in python:\n",
    "https://www.w3schools.com/python/ref_string_replace.asp\n",
    "https://www.tutorialspoint.com/python/string_replace.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from the sales per unit column values\n",
    "\n",
    "df.sales_per_unit_in_thousands_2019 = #__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from the franchised units column values\n",
    "\n",
    "df.franchised_units_2019 = #__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from the company owned units column values\n",
    "\n",
    "df.company_owned_units_2019 = #__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from the total units column values\n",
    "\n",
    "df.total_units_2019 =  #__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first few values in your dataframe to see if commas were taken out successfully\n",
    "\n",
    "# __TO_DO__ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! We ran into another problem. If you look in the third row under the \"company_owned_units_2019\" column, you'll see a value listed as \"NaN.\" This stands for \"not a number.\" We won't be able to convert these columns to numbers as long as there are NaN values in the columns. This is a common problem for data analysts to need to solve. There are many ways to fill in blank values or missing fields in datasets, which you'll learn about as you move further in the specialization. \n",
    "\n",
    "For now, we will use the simplest method of replacing NaN fields with 0. Run the cells below to fix the NaN issues in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell. First we'll take a look at any rows with NaN values.\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell - now we will fill the NaN values with zero\n",
    "\n",
    "df.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .head() method on the data frame to see if we fixed the NaN values\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the third row under company_owned_units - The value should now be 0. Simple, easy fix! \n",
    "\n",
    "If you'd like to learn more about the Pandas fillna method, click here - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we fixed our NaN values, we're ready to convert these columns into integers instead of strings.  We'll use the Pandas dataframe.astype() method to convert the values. See the first example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT + ENTER to run this cell. below is an example of the pandas astype() method on the first column we are changing\n",
    "\n",
    "df.sales_in_millions_2019 = df.sales_in_millions_2019.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example above, change the column values to integers for sales per unit, franchised units, company owned units, total units, and unit changes from 2018. \n",
    "\n",
    "If you'd like to read more on the Pandas dataframe.astype() method, click here - https://www.geeksforgeeks.org/python-pandas-dataframe-astype/#:~:text=astype()%20method%20is%20used,type%20to%20another%20data%20type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sales per unit column datatype to integer\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change franchised column datatype to integer\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change company owned column datatype to integer\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change total units column datatype to integer\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change unit change from 2018 column datatype to integer\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check that our conversions ran successfully. Use the info method on the dataframe to ensure the comlumns above now say int32 under the Dtypes section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the info method on the dataframe to check the datatypes\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great job! We now have a clean dataframe that is ready to explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Explore and Analyze the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the data, we will use pandas methods to analyze the data and the matplotlib and seaborn libraries to visualize it. Matplotlib and Seaborn are libraries in Python which make graphs and other visualizations using data.\n",
    "\n",
    "We already imported MatPlotLib as \"plt\" and Seaborn as \"sns\" in the beginning of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the questions we outlined in Step 1 to guide our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1 - What is the distribution of revenue of all companies? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this, we can use the .describe() method from pandas on the data frame. To do this, reference the dataframe (df), then use dot notation to reference the particular column (sales_in_millions_2019), then invoke the describe method.  \n",
    "\n",
    "If you'd like to read more about the Pandas .describe(), click here - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the describe method on the sales in millions column to see revenue distribution \n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above the distribution of the revenue for the companies overall. These measurements are an important tool in data analytics to get an overall idea of numbers in a dataset. \n",
    "\n",
    "This group of numbers is often referred to as a \"Five Number Summary\" in statistics. In a five number summary, we can see the minimum value, first quartile, the median (or middle value), third quartile, and maximum value. The Pandas describe method also gives us the count, which is the number of values in the dataset, and the mean, which is the average value in the dataset. \n",
    "\n",
    "If you're interested in learning more, read here about the five number summary - https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch12/5214877-eng.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can visualize the five number summary with something called a Box Plot. Run the cell below to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell and see a visualization of the describe() method above\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax = sns.boxplot(x=df.sales_in_millions_2019)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Sales in Millions (2019)\")\n",
    "ax.set_title(\"Distribution of Sales for Top 50 Fast Food Companies in U.S. (2019)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the box plot above, the left-most line is the minimum number, the first colored section is the first quartile, the line separating the two colored sections is the median, the second colored section is the third quartile, the right-most line is the upper end of the fourth quartile, and the dots extending to the right of the graph are the outliers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to read more about box plots and see additional examples, look at the Seaborn boxplot documentation here - https://seaborn.pydata.org/generated/seaborn.boxplot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #2 - What is the distribution for the total number of units for the companies overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Question #1 as a guide, use the describe method and boxplot methods to answer the question, \"What is the distribution for the total number of units for the companies overall?\" The code comments will help you know what to do. Only fill in sections which say \"#__TO_DO__#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the describe method on the total_units_2019 column to see total unit distribution\n",
    "\n",
    "#__TO_DO__#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a boxplot in Seaborn to display the distribution above. Only fill in the #__TO_DO__# sections\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax = #__TO_DO__#\n",
    "\n",
    "ax.set_xlabel(\"Total Units (2019)\")\n",
    "ax.set_title(\"Distribution of Total Units for Top 50 Fast Food Companies in U.S. (2019)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You made a boxplot. Let's move on to question #3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3 - What companies have the most franchise units?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this visualization, we'll use a bar graph. A bar graph displays categorical data (in this case, number of franchise units for each company). Bar graphs are different than histograms, which display numbers over time. In specializations you'll learn many more types of visualizations, including how to pick the best visualization to represent the particular data you're working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell\n",
    "\n",
    "# uses seaborn (sns) and matplotlib (plt) to set graph style and size\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# sets our visualization to variable named \"ax\" / sets data and x and y variables\n",
    "ax = sns.barplot(data=df, x=df.company, y=df.franchised_units_2019)\n",
    "\n",
    "# references figure variable name (ax) to change labels of x and y axis and graph title\n",
    "ax.set_xlabel(\"Company Name\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylabel(\"Total Franchised Units\")\n",
    "ax.set_title(\"Total Franchised Units of Top 50 Fast Food Companies in U.S.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's answer our question - looking at our graph above, which are the five companies with the highest number of franchise locations? Write your answers in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__TO_DO__#\n",
    "\n",
    "\"\"\"\n",
    "The following 5 companies have the highest amount of franchised locations:\n",
    "\n",
    "1) #__TO_DO__#\n",
    "2) #__TO_DO__#\n",
    "3) #__TO_DO__#\n",
    "4) #__TO_DO__#\n",
    "5) #__TO_DO__#\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your answers by running the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run this cell. \n",
    "\n",
    "df[['company', 'franchised_units_2019']].sort_values(by=\"franchised_units_2019\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the sort_values method from Pandas to get our answer above. To read more about this method, click here - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the methods for Question #3, you should able to answer question #4 on your own! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4 - Which companies have the most locations combined? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar graph showing the number of total units for all companies. Fill in only the #__TO_DO__# portions\n",
    "\n",
    "# uses seaborn (sns) and matplotlib (plt) to set graph style and size\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "#__TO_DO__# - follow instructions below\n",
    "\n",
    "# set the visualization to variable named \"ax\" \n",
    "# use sns.barplot \n",
    "# set data as df, and x and y variables as company and total_units_2019 column \n",
    "\n",
    "\n",
    "#__TO_DO__# - fill in #__TO_DO__# sections with appropriate titles describing the graph\n",
    "\n",
    "ax.set_xlabel(#__TO_DO__#) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylabel(#__TO_DO__#) \n",
    "ax.set_title(#__TO_DO__#); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above, list which companies have the highest number of total units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__TO_DO__#\n",
    "\n",
    "\"\"\"\n",
    "The following 5 companies have the highest amount of total unit locations:\n",
    "\n",
    "1) #__TO_DO__#\n",
    "2) #__TO_DO__#\n",
    "3) #__TO_DO__#\n",
    "4) #__TO_DO__#\n",
    "5) #__TO_DO__#\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__TO_DO__# - follow instructions below\n",
    "\n",
    "# check your results by using the sort_values method like we did for question #3 - fill in only the #__TO_DO__# sections\n",
    "\n",
    "df[['company', 'total_units_2019']].sort_values(by=#__TO_DO__#, ascending=#__TO_DO__#).head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Lastly, use these same methods to answer question #5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5 - Which companies have the highest revenue per unit? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar graph showing the revenue per unit for all companies. Fill in only the #__TO_DO__# portions\n",
    "\n",
    "# uses seaborn (sns) and matplotlib (plt) to set graph style and size\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "#__TO_DO__# - follow instructions below\n",
    "\n",
    "# set the visualization to variable named \"ax\" \n",
    "# use sns.barplot \n",
    "# set data as df, and x and y variables as company and sales_per_unit_2019 column \n",
    "\n",
    "\n",
    "#__TO_DO__# - fill in #__TO_DO__# sections with appropriate titles describing the graph\n",
    "\n",
    "ax.set_xlabel(#__TO_DO__#) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylabel(#__TO_DO__#) \n",
    "ax.set_title(#__TO_DO__#); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above, list which 5 companies have the highest revenue per unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__TO_DO__#\n",
    "\n",
    "\"\"\"\n",
    "The following 5 companies have the highest amount of total unit locations:\n",
    "\n",
    "1) #__TO_DO__#\n",
    "2) #__TO_DO__#\n",
    "3) #__TO_DO__#\n",
    "4) #__TO_DO__#\n",
    "5) #__TO_DO__#\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your answers by using the sort_values method on the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your results by using the sort_values method like we did for question #3 - fill in only the #__TO_DO__# sections\n",
    "\n",
    "df[['company', 'sales_per_unit_in_thousands_2019']].sort_values(#__TO_DO__#).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You've used data analysis and visualizations to explore a dataset and answer questions. \n",
    "\n",
    "For our last questions, we will be delving deeper into statistical analysis methods. You won't have to complete any of this on your own - just run the cells and read through the explanations to see the next step of what's possible in data analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #6 - Is there a correlation between the amount of sales per company and the company's total number of locations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we will be using the \"pearsonr\" method, which is calculated for us using the scipy.stats python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the pearsonr method from the scipy stats library\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pearsonr method finds the correlation coefficient and the p-value from two continuous variables. \n",
    "\n",
    "For correlation, the closer the coefficient is to -1 or 1, the stronger the correlation between the two variables is. For example, -0.8 is a strong negative correlation and 0.6 is a moderate positive correlation. \n",
    "\n",
    "The second number is a p-value. A p-value tells you whether or not a finding is statistically significant. You don't need to know everything about how this works, just know that any p-vale under 0.05 is considered statistically significant.\n",
    "\n",
    "In a pearsonr result, the first number is the correlation coefficient and the second number is the p-value. For example, if a pearsonr result is (-0.9, .00000126), the correlation coefficient is -0.9 and the p-value is .00000126. \n",
    "\n",
    "We'll run the pearsonr method in the cell below comparing the total units and sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press SHIFT+ENTER to run the pearsonr method on the total units and total sales\n",
    "\n",
    "pearsonr(df.total_units_2019, df.sales_in_millions_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in our result, the correlation coefficient is 0.716 and the p-value is .00000000497 (written in scientific notation). \n",
    "\n",
    "Interpreting this, we can see that there is a ***moderately strong positive correlation which is statistically significant*** between a company's total units and a company's total sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a visualization of this correlation below with a seaborn linear regression plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(font_scale=1.5)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "ax = sns.regplot(x=df['total_units_2019'], y=df['sales_in_millions_2019'])\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Total Company Units (2019)\")\n",
    "ax.set_ylabel(\"Total Sales in Millions (2019)\")\n",
    "ax.set_title(\"Relationship Between Companies' Total Units and Total Sales\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Validate Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 in the data analysis lifecycle is to validate findings. In data analysis projects using forecasting, finding correlations, machine learning models, etc, it is important to run many analyses and look for vulnerabilities in the models to validate findings. \n",
    "\n",
    "Ronald Coase, a famous economist, said, \"If you torture the data long enough, it will confess to anything.\"\n",
    "\n",
    "In data analytics, we have to analyze data without changing or manipulating the meaning of it. \n",
    "\n",
    "This step is a check-point to make sure every step in the process was done correctly. Was the data we chose the correct data to be used to answer the questions we had? Did we clean it properly? When we manipulated the data, did we change the integrity of the dataset as a whole? Did we run our analyses correctly? Are our visualizations correct and honest? \n",
    "\n",
    "Part of the job of a data analyst is not only to find answers and communicate them - but to find the ***appropriate answers*** and communicate them with integrity. Even when answers might not be what your boss wants to hear - it is still important to just stick to the numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in the data analysis process is communicating results. This can take many forms depending on your company and objectives. You might write reports, make slideshow presentations, put the information onto a website, or make interactive dashboards. \n",
    "\n",
    "Go through the links below to see examples of possible ways to communicate your findings as a data analyst:\n",
    "\n",
    "***Data Stories gallery with Microsoft PowerBI*** - https://community.powerbi.com/t5/Data-Stories-Gallery/bd-p/DataStoriesGallery\n",
    "\n",
    "***Business Intelligence Dashboard examples on Tableau*** - https://www.tableau.com/learn/articles/business-intelligence-dashboards-examples\n",
    "\n",
    "***Streamlit web application - data visualization examples*** - https://streamlit.io/gallery?category=data-visualization\n",
    "\n",
    "***DevMountain Data Analytics capstone example*** - http://stetsdata.com/ (web application with visual data analysis of US hate crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further information on communicating results and storytelling with data, watch this 13 minute video on pluralsight:\n",
    "\n",
    "#### Communicating Data through Storytelling: Executive Briefing with Jordan Morrow - \n",
    "https://app.pluralsight.com/course-player?courseId=93f0ff42-ecad-4409-9344-178c28328b01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other questions might you want to know before building your new franchise? What data would you need to gather to answer these questions? For example, you might want to know what average revenue looks like for that particular company and area, where exactly in the area would lead to the most profit, how many employees you'll need to hire in the beginning, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis is never-ending. Much of your work as an analyst will consist of questioning, analyzing, finding results, then being led to more questions based on your findings and repeating the process again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope you enjoyed the Data Analytics Specialization trial! If you have additional questions, reach out to your foundations instructor to get in touch with the Data Analytics tech lead. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
